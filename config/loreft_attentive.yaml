defaults:
  - _self_
  - task: base
  - override hydra/launcher: ray_jobs

hydra:
  launcher:
    poll_jobs: false
    entrypoint_num_gpus: 1

# Model settings
model:
  name: "yahma/llama-7b-hf"
  dtype: "bfloat16"
  max_length: 512

# Training settings
training:
  seed: 42
  epochs: 1
  batch_size: 4
  eval_batch_size: 4
  gradient_accumulation_steps: 4
  learning_rate: 5e-3
  schedule: "linear"
  warmup_ratio: 0.0
  weight_decay: 0.0
  dropout: 0.0
  logging_steps: 1
  eval_strategy: steps
  eval_steps: 100

# Intervention settings
intervention:
  type: "TokenSelectiveLoreftIntervention"
  layers: "2;10;18;26"
  rank: 8
  position: "f256+l256"
  act_fn: null
  add_bias: false
  share_weights: false
  # For token selective attn module
  num_heads: 4
  start_temperature: 1
  end_temperature: 1e-3

# LoRA settings
lora:
  use_lora: false
  disable_reft: false
  rank: 8
  alpha: 32
  modules: "o_proj"
  layers: "2;10;18;26"

# Logging settings
logging:
  is_wandb: false
  wandb_name: null
  wandb_proj: "HyperReFT"
  wandb_entity: "sidharth-baskaran-georgia-institute-of-technology"
  output_dir: "assets/official_results"
  save_model: false

generation:
  greedy_decoding: false
  temperature: null
  top_k: null
  top_p: null